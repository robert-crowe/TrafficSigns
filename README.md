# German Traffic Sign Recognition

Robert Crowe

v1.0

4 Jan 2017

This is an implementation of a convolutional network classifier for the German Traffic Sign
dataset.  You'll need a copy of the dataset, which is available at:

>http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset
    
The architecture is based on a paper by Pierre Sermanet and Yann LeCun:

>Traffic Sign Recognition with Multi-Scale Convolutional Networks
    http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf

## Preprocessing:

I converted to YUV, but I wasn't sure if the original was RGB or BGR, so I tried some samples with 
both. I seemed to have better contrast with RGB, so I chose to stay with that. Then I took only the 
Y channel as the final image, based on the phase 2 result of the Sermanet/LeCunn paper.

The Sermanet/LeCunn paper applies both global and local contrast normalization (see III-A.2):

>_"The Y channel is then preprocessed with global and local contrast normalization while U and V channels 
are left unchanged. Global normalization first centers each image around its mean value, whereas local 
normalization (see II-B) emphasizes edges."_

My intent was to mirror the approach in the paper, which seemed like a reasonable place to start. I was 
able to duplicate everything except the local contrast normalization (LCN), due to time constraints. 
Unfortunately the only implementations of LCN that I was able to find were all in Theano, so I would 
be forced to rewrite them in something else or bring in all of Theano. Bringing in all of Theano seemed 
too massive to be practical, and I have not yet had time to work through a new implementation of LCN.

As a similar substitute for LCN I decided to use local response normalization (LRN), which is available 
in Tensorflow. LRN is similar to LCN, but does not subtract the mean. (See AlexNet paper for a comparison 
of LCN and LRN)

## Model:

I chose to start with an implementation as close as possible to the Sermanet/LeCunn paper, since they had done 
extensive work with this dataset and achieved impressive results. From there I could begin attempting to make 
improvements if the accuracy was not acceptable. However in this case the accuracy was very impressive (99.99% 
accuracy on the test set), so I chose to stay with that.

The architecture uses two convolutional layers for feature extraction, followed by two fully connected layers 
for classification. Each convolutional layer is followed by a max polling layer and a normalization layer using 
LRN (see above). The layer sizes were roughly defined in the paper, but I was required to choose a filter size - 
I chose 5x5 for both convolutional layers. For the max pooling I chose 2x2.

One unique feature of this architecture is that the outputs from both convolutional layers ("stage 1" and "stage 2") 
are fed to the first fully connected layer. That means that the classifier is given both the fairly simple features 
generated by the first layer, and the more complex features generated by the second layer. This is the approach 
used by Sermanet/LeCunn and is supported by their results.