""" German Traffic Sign Recognition

Robert Crowe
v1.0
4 Jan 2017

This is an implementation of a convolutional network classifier for the German Traffic Sign
dataset.  You'll need a copy of the dataset, which is available at:

    http://benchmark.ini.rub.de/?section=gtsrb&subsection=dataset

The architecture is based on a paper by Pierre Sermanet and Yann LeCun:

    Traffic Sign Recognition with Multi-Scale Convolutional Networks
    http://yann.lecun.com/exdb/publis/pdf/sermanet-ijcnn-11.pdf

Preprocessing:

I converted to YUV, but I wasn't sure if the original was RGB or BGR, so I tried some samples with 
both. I seemed to have better contrast with RGB, so I chose to stay with that. Then I took only the 
Y channel as the final image, based on the phase 2 result of the Sermanet/LeCunn paper.

The Sermanet/LeCunn paper applies both global and local contrast normalization (see III-A.2):

"The Y channel is then preprocessed with global and local contrast normalization while U and V channels 
are left unchanged. Global normalization first centers each image around its mean value, whereas local 
normalization (see II-B) emphasizes edges."

My intent was to mirror the approach in the paper, which seemed like a reasonable place to start. I was 
able to duplicate everything except the local contrast normalization (LCN), due to time constraints. 
Unfortunately the only implementations of LCN that I was able to find were all in Theano, so I would 
be forced to rewrite them in something else or bring in all of Theano. Bringing in all of Theano seemed 
too massive to be practical, and I have not yet had time to work through a new implementation of LCN.

As a similar substitute for LCN I decided to use local response normalization (LRN), which is available 
in Tensorflow. LRN is similar to LCN, but does not subtract the mean. (See AlexNet paper for a comparison 
of LCN and LRN)

Model:

I chose to start with an implementation as close as possible to the Sermanet/LeCunn paper, since they had done 
extensive work with this dataset and achieved impressive results. From there I could begin attempting to make 
improvements if the accuracy was not acceptable. However in this case the accuracy was very impressive (99.99% 
accuracy on the test set), so I chose to stay with that.

The architecture uses two convolutional layers for feature extraction, followed by two fully connected layers 
for classification. Each convolutional layer is followed by a max polling layer and a normalization layer using 
LRN (see above). The layer sizes were roughly defined in the paper, but I was required to choose a filter size - 
I chose 5x5 for both convolutional layers. For the max pooling I chose 2x2.

One unique feature of this architecture is that the outputs from both convolutional layers ("stage 1" and "stage 2") 
are fed to the first fully connected layer. That means that the classifier is given both the fairly simple features 
generated by the first layer, and the more complex features generated by the second layer. This is the approach 
used by Sermanet/LeCunn and is supported by their results.

"""

import GCN
import batcher
import model

import pickle
import numpy as np
import tensorflow as tf
import cv2

training_file = './train.p'
testing_file = './test.p'

with open(training_file, mode='rb') as f:
    train = pickle.load(f)
with open(testing_file, mode='rb') as f:
    test = pickle.load(f)
    
X_train, y_train = train['features'], train['labels']
X_test, y_test = test['features'], test['labels']

# Number of training examples
n_train = len(y_train)

# Number of testing examples.
n_test = len(y_test)

# What's the shape of an traffic sign image?
image_shape = X_train.shape[1:]

# How many unique classes/labels/types of traffic sign there are in the dataset.
n_classes = len(np.unique(y_train))

# Preprocessing
def applyGCN(img):
    flatimg = np.array(np.reshape(img, 32*32), ndmin=2)
    gcn = GCN.global_contrast_normalize(flatimg, scale=1., 
                                subtract_mean=True, use_std=True,
                                sqrt_bias=10., min_divisor=1e-8)
    return gcn.reshape((32, 32, 1))

# Mapping to YUV, taking only Y, and applying Global Contrast Normalization
YUV_train = np.array(list(map(lambda img: cv2.cvtColor(img, cv2.COLOR_RGB2YUV), X_train)))
justY_train = YUV_train[:,:,:,0]
GCN_train = np.array(list(map(lambda img: applyGCN(img), justY_train)))

YUV_test = np.array(list(map(lambda img: cv2.cvtColor(img, cv2.COLOR_RGB2YUV), X_test)))
justY_test = YUV_test[:,:,:,0]
GCN_test = np.array(list(map(lambda img: applyGCN(img), justY_test)))

print('GCN_train is a {} with shape {}'
      .format(type(GCN_train), GCN_train.shape))

print('y_train is a {} with shape {}'
      .format(type(y_train), y_train.shape))

def main():
    # Parameters
    learning_rate = 0.005
    batch_size = 32
    test_batch_size = 128
    training_epochs = 10

    # Use logits as a proxy to test whether we've already defined everything
    try:
        defined_test = logits
    except NameError:
        print('logits did not exist, creating')
        # tf Graph input
        x = tf.placeholder("float", [None, 32, 32, 1], name='X_placeholder')
        y = tf.placeholder("float", [None, n_classes], name='Y_placeholder')
        # Define model
        logits = model.SignModel(x, n_classes)
        # Define loss and optimizer
        cost = tf.reduce_mean(
            tf.nn.softmax_cross_entropy_with_logits(logits, y))
        optimizer = tf.train.GradientDescentOptimizer(
            learning_rate=learning_rate).minimize(cost)
    else:
        print('Model, variables, placeholders, and operations already defined')

    last_cp = tf.train.latest_checkpoint('.', latest_filename=None)
    if (last_cp is None):
        print('Checkpoint not found')
        # Initializing the variables
        init = tf.global_variables_initializer()
    else:
        print('Checkpoint found: {}'.format(last_cp))

    # Add ops to save and restore all the variables.
    saver = tf.train.Saver()

    # Launch the graph
    with tf.Session() as sess:
        if (last_cp is not None):
            # Restore variables from disk.
            print('Restoring: {}'.format(last_cp))
            saver.restore(sess, last_cp)
        else:
            print('No checkpoint to restore, initializing')
            sess.run(init)
            
        # Training cycle
        data = batcher.Batcher(GCN_train, y_train)
        
        for epoch in range(training_epochs):
            total_batch = int(n_train/batch_size)
            # Loop over all batches
            for i in range(total_batch):
                batch_x, batch_y = data.next_batch(batch_size)
                # Run optimization op (backprop) and cost op (to get loss value)
                sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})
            # Display logs per epoch step
            c = sess.run(cost, feed_dict={x: batch_x, y: batch_y})
            print("Epoch:", '%04d' % (epoch+1), "cost=", "{:.9f}".format(c))
            
        print("Optimization Finished!")
        
        # Save the variables to disk.
        save_path = saver.save(sess, "./SignsModel.ckpt")
        print("Model saved in file: %s" % save_path)
        
        # Test model
        correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))
        
        # Calculate accuracy in batches to avoid running out of memory
        accuracy = tf.reduce_mean(tf.cast(correct_prediction, "float"))
        testdata = batcher.Batcher(GCN_test, y_test)
        test_batches = int(n_test/test_batch_size)
        # Loop over all batches
        total_acc = 0
        for i in range(test_batches):
            test_batch_x, test_batch_y = data.next_batch(test_batch_size)
            total_acc += accuracy.eval({x: test_batch_x, y: test_batch_y})
            
        print("Accuracy:", total_acc / test_batches)

if __name__ == "__main__":
    main()